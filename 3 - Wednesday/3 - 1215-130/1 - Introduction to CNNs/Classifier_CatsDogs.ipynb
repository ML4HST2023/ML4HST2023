{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523a2ab8",
   "metadata": {},
   "source": [
    "A classifier to classify images of dogs and cats\n",
    "In the implementation the use of ImageFolder to load data\n",
    "is demonstrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "\n",
    "#Import data manipulation libraries\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import PyTorch data processing libraries\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3658000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create transforms\n",
    "#Create a transform with resizing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize([64,64]),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create path to dataset\n",
    "data_dir ='D:/ML4HST_2023/Datasets/DogsCats'\n",
    "#Create train dataset\n",
    "train_dataset = datasets.ImageFolder(data_dir+'\\Train',transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(data_dir+'\\Val',transform=transform_train)\n",
    "\n",
    "print('Train Set: ',len(train_dataset))\n",
    "print('Valid Set: ',len(val_dataset))\n",
    "print(train_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datloaders for training and validation data sets\n",
    "batch_size = 32\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "print(len(train_dl))\n",
    "print(len(valid_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Sample Images\n",
    "samples, labels = next(iter(DataLoader(train_dataset, batch_size=4, shuffle=True)))\n",
    "plt.figure(figsize=(16,24))\n",
    "grid_imgs = torchvision.utils.make_grid(samples[:4])\n",
    "np_grid_imgs = grid_imgs.numpy()\n",
    "#Display the shape of the grid containing four images each of size 64x64. The black border will increase the size.\n",
    "print(np_grid_imgs.shape)\n",
    "#imshow of matplotlib requires the images in the format(WHC)\n",
    "plt.imshow(np.transpose(np_grid_imgs, (1,2,0)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the CNN Architecture\n",
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1))\n",
    "model.add_module('relu1', nn.ReLU())        \n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))  \n",
    "\n",
    "model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))\n",
    "model.add_module('relu2', nn.ReLU())        \n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))   \n",
    "\n",
    "model.add_module('conv3', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1))\n",
    "model.add_module('relu3', nn.ReLU())        \n",
    "model.add_module('pool3', nn.MaxPool2d(kernel_size=2))   \n",
    "\n",
    "model.add_module('conv4', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1))\n",
    "model.add_module('relu4', nn.ReLU())\n",
    "#Add a average pooling\n",
    "model.add_module('pool4', nn.AvgPool2d(kernel_size=8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85564183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the output of the last pooling layer\n",
    "model.add_module('flatten', nn.Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feeb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a fully connected output layer with a single neuron\n",
    "model.add_module('fc', nn.Linear(256, 1)) \n",
    "model.add_module('sigmoid', nn.Sigmoid()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e709b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the model details\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup to use GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Binary Cross Entropy loss function \n",
    "loss_fn = nn.BCELoss()\n",
    "#Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c87a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a training function\n",
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device) \n",
    "            y_batch = y_batch.to(device) \n",
    "            pred = model(x_batch)[:, 0]\n",
    "            loss = loss_fn(pred, y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device) \n",
    "                y_batch = y_batch.to(device) \n",
    "                pred = model(x_batch)[:, 0]\n",
    "                loss = loss_fn(pred, y_batch.float())\n",
    "                loss_hist_valid[epoch] += loss.item()*y_batch.size(0) \n",
    "                is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "                accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: {accuracy_hist_train[epoch]:.4f} val_accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee082586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Training\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "#plt.savefig('figures/14_17.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model performance with test data\n",
    "test_dataset = datasets.ImageFolder(data_dir+'\\Test',transform=transform_train)\n",
    "print('Test Set: ',len(test_dataset))\n",
    "test_dl = DataLoader(test_dataset,batch_size, shuffle=False)\n",
    "accuracy_test = 0.0\n",
    "\n",
    "#Set the model for evaluation using the model on GPU\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch,y_batch in test_dl:\n",
    "        x_batch = x_batch.to(device) \n",
    "        y_batch = y_batch.to(device)\n",
    "        pred = model(x_batch)[:,0]\n",
    "        is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "        accuracy_test += is_correct.sum()\n",
    "\n",
    "accuracy_test /= len(test_dataset)\n",
    "print('Test Accuracy: {0:.4f}'.format(accuracy_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e26f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the results for a small subset of test data with their probabilities\n",
    "model = model.to('cpu')\n",
    "samples, labels = next(iter(DataLoader(test_dataset, batch_size=32, shuffle=True)))\n",
    "pred = model(samples)[:,0]*100\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "for j in range(10,20):\n",
    "    ax = fig.add_subplot(2,5,j-10+1)\n",
    "    ax.set_xticks([]);ax.set_yticks([])\n",
    "    ax.imshow(samples[j].permute(1,2,0))\n",
    "    if labels[j] == 1:\n",
    "        label = 'dog'\n",
    "    else:\n",
    "        label = 'cat'\n",
    "    ax.text(\n",
    "        0.5,-0.15,\n",
    "        f'GT:{label:s}\\nPr({label:s})={pred[j]:.0f}%',\n",
    "        size = 16,\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center',\n",
    "        transform=ax.transAxes\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828e9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
