{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8e20b886",
   "metadata": {},
   "source": [
    "A program to implement a Convolution GAN to generate fake digits from MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfbb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Import dataset class for downloading MNIST datasets\n",
    "from torch.utils.data import Dataset\n",
    "# Import torchvision libraries\n",
    "import torchvision\n",
    "# Import transforms class for image processing\n",
    "from torchvision import transforms \n",
    "# Import dataloader class to load the data from datasets\n",
    "from torch.utils.data import DataLoader\n",
    "# Import numpy for numeric computation\n",
    "import numpy as np\n",
    "# Import matplotlib for displaying plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ba6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Display the device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab34073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to generate random noise\n",
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    # Uniform distribution\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size, 1, 1)*2 - 1 \n",
    "    # Normal distribution\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size, 1, 1)\n",
    "    return input_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75366c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data loader\n",
    "\n",
    "# Create an image path on the current location\n",
    "image_path = './'\n",
    "# Create a transforms function to process the image  \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "\n",
    "# Get datasets from torchvision MNIST datasets\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Set the seed for generating random numbers\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# Set up the dataset\n",
    "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size, \n",
    "                      shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffb00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to creator generator network\n",
    "def make_generator_network(input_size, n_filters):\n",
    "    model = nn.Sequential(\n",
    "        # Input size, n_filters: output size, 4: kernel size, 1: stride, 0: padding, bias flag: False \n",
    "        nn.ConvTranspose2d(input_size, n_filters*4, 4, 1, 0, bias=False),\n",
    "        # Perform batch normalization\n",
    "        nn.BatchNorm2d(n_filters*4),\n",
    "        # Use the leaky ReLU\n",
    "        nn.LeakyReLU(0.2),\n",
    "        # Perform 2D Transpose Convolution\n",
    "        nn.ConvTranspose2d(n_filters*4, n_filters*2, 3, 2, 1, bias=False),\n",
    "        # Perform batch normalization\n",
    "        nn.BatchNorm2d(n_filters*2),\n",
    "        # Use the leaky ReLU\n",
    "        nn.LeakyReLU(0.2),\n",
    "        # Perform 2D Transpose Convolution\n",
    "        nn.ConvTranspose2d(n_filters*2, n_filters, 4, 2, 1, bias=False),\n",
    "        # Perform batch normalization\n",
    "        nn.BatchNorm2d(n_filters),\n",
    "        # Use the leaky ReLU\n",
    "        nn.LeakyReLU(0.2),\n",
    "        # Perform 2D Transpose Convolution\n",
    "        nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
    "        # Use tanh function\n",
    "        nn.Tanh())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "        # Create a neural network model\n",
    "        self.network = nn.Sequential(\n",
    "            # Perform 2D Convolution\n",
    "            nn.Conv2d(1, n_filters, 4, 2, 1, bias=False),\n",
    "            # Use the leaky ReLU\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Perform 2D Convolution\n",
    "            nn.Conv2d(n_filters, n_filters*2, 4, 2, 1, bias=False),\n",
    "            # Perform batch normalization\n",
    "            nn.BatchNorm2d(n_filters * 2),\n",
    "            # Use the leaky ReLU\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Perform 2D Convolution\n",
    "            nn.Conv2d(n_filters*2, n_filters*4, 3, 2, 1, bias=False),\n",
    "            # Perform batch normalization\n",
    "            nn.BatchNorm2d(n_filters*4),\n",
    "            # Use the leaky ReLU\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # Perform 2D Convolution\n",
    "            nn.Conv2d(n_filters*4, 1, 4, 1, 0, bias=False),\n",
    "            # Use the sigmoid activation function\n",
    "            nn.Sigmoid())\n",
    "    # Forward pass\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the random noise\n",
    "z_size = 100\n",
    "# Size of the image\n",
    "image_size = (28, 28)\n",
    "# Filter size\n",
    "n_filters = 32\n",
    "# Create a generator netowrk on GPU\n",
    "gen_model = make_generator_network(z_size, n_filters).to(device)  \n",
    "# Display the generator model\n",
    "print(gen_model)\n",
    "# Create a discriminator network on GPU\n",
    "disc_model = Discriminator(n_filters).to(device)     \n",
    "# Display the discriminator model\n",
    "print(disc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizers\n",
    "\n",
    "# Set the loss function as Binary Cross Entropy loss\n",
    "loss_fn = nn.BCELoss()\n",
    "# Use Adam optimizer for generator model parameters\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0003)\n",
    "# Use Adam optimizer for discriminator model parameters\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "def d_train(x):\n",
    "    disc_model.zero_grad()\n",
    "\n",
    "    # Get the batch size\n",
    "    batch_size = x.size(0)\n",
    "    # Send the discriminator to GPU\n",
    "    x = x.to(device)\n",
    "    # Label the real data\n",
    "    d_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "    # Get the probability of real data\n",
    "    d_proba_real = disc_model(x)\n",
    "    # Get the loss of real data\n",
    "    d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
    "\n",
    "    # Train discriminator on a fake batch\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_output = gen_model(input_z)\n",
    "    # Get the probability of fake data\n",
    "    d_proba_fake = disc_model(g_output)\n",
    "    # Label the fake data\n",
    "    d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
    "    # Get the loss of fake data\n",
    "    d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
    "\n",
    "    # Perform backpropagaton by combining real and fake loss variable\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "  \n",
    "    return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generator\n",
    "def g_train(x):\n",
    "    gen_model.zero_grad()\n",
    "    \n",
    "    # Get the batch size\n",
    "    batch_size = x.size(0)\n",
    "    # Create noise in GPU \n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    # Label the real data\n",
    "    g_labels_real = torch.ones((batch_size, 1), device=device)\n",
    "    # Get output from the generated model\n",
    "    g_output = gen_model(input_z)\n",
    "    # Get the probability of the fake model \n",
    "    d_proba_fake = disc_model(g_output)\n",
    "    # Get the generator loss using probability of fake data and real labels\n",
    "    g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
    "    # Perform backpropagation\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "        \n",
    "    return g_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bca08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create various samples using generator\n",
    "def create_samples(g_model, input_z):\n",
    "    g_output = g_model(input_z)\n",
    "    images = torch.reshape(g_output, (batch_size, *image_size))    \n",
    "    return (images+1)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ef4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random noise distrubution model\n",
    "mode_z = 'normal'\n",
    "# Generate a noise using the distribution model\n",
    "fixed_z = create_noise(batch_size, z_size, mode_z).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the array for storing the images at different epoch samples\n",
    "epoch_samples = []\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# Set the seed for generating random numbers\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#Start training the model\n",
    "for epoch in range(1, num_epochs+1):    \n",
    "    gen_model.train()\n",
    "    d_losses, g_losses = [], []\n",
    "    for i, (x, _) in enumerate(mnist_dl):\n",
    "        d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_train(x))\n",
    " \n",
    "    print(f'Epoch {epoch:03d} | Avg Losses >>'\n",
    "          f' G/D {torch.FloatTensor(g_losses).mean():.4f}'\n",
    "          f'/{torch.FloatTensor(d_losses).mean():.4f}')\n",
    "    gen_model.eval()\n",
    "    epoch_samples.append(\n",
    "        create_samples(gen_model, fixed_z).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa89e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set different epochs to display \n",
    "selected_epochs = [1, 2, 4, 10, 25, 50]\n",
    "# Create a figure plot to display generated numbers\n",
    "fig = plt.figure(figsize=(10, 14))\n",
    "# Display generated numbers at different epochs\n",
    "for i,e in enumerate(selected_epochs):\n",
    "    for j in range(6):\n",
    "        ax = fig.add_subplot(6, 6, i*6+j+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if j == 0:\n",
    "            ax.text(\n",
    "                -0.06, 0.5, f'Epoch {e}',\n",
    "                rotation=90, size=18, color='red',\n",
    "                horizontalalignment='right',\n",
    "                verticalalignment='center', \n",
    "                transform=ax.transAxes)\n",
    "        \n",
    "        image = epoch_samples[e-1][j]\n",
    "        ax.imshow(image, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642794f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
