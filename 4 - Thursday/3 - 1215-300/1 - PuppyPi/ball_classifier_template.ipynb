{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Import necessary libraries ----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2727236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Set up training data directories ----\n",
    "base_dir = \"data/\"\n",
    "\n",
    "\n",
    "# Define image transforms to convert images to tensor and normalize\n",
    "image_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])])\n",
    "\n",
    "# Use ImageFolder object to simplify data loading\n",
    "train_dataset = ImageFolder(os.path.join(base_dir, 'train/'), transform=image_transform)\n",
    "test_dataset = ImageFolder(os.path.join(base_dir, 'test/'), transform=image_transform)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create data loader objects\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Define CNN model for multiclass classification ----\n",
    "NUM_OUTPUT_CLASSES = 5\n",
    "\n",
    "model = nn.Sequential()\n",
    "\n",
    "# First block of convolution -> ReLU -> MaxPooling\n",
    "model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels = 8, kernel_size=3, padding=0))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=4))\n",
    "\n",
    "# Second block of convolution -> ReLU -> MaxPooling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Third block of convolution -> ReLU -> MaxPooling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Flatten layer to transform feature maps into 1D vector\n",
    "\n",
    "\n",
    "# Output layer: must set output size to number of classes\n",
    "\n",
    "\n",
    "# Display model iformation\n",
    "model\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable model parameters: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Set compute device and send model, set up optimizer and loss function ----\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Cross Entropy is the go-to loss function for multiclass classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62460a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, val_dataloader, opt, criterion, num_epochs):\n",
    "    total_time = 0.0\n",
    "    \n",
    "    # ###### TRAINING ######\n",
    "    model.train()\n",
    "    # Iterate through number of training epochs\n",
    "    for n in range(num_epochs):\n",
    "        # Initialize values for running statistics\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_correct = 0\n",
    "        counter = 0\n",
    "        start = time.time()\n",
    "        # Iterate through training data set\n",
    "        for data, target in dataloader:\n",
    "            # Send input and targets to compute device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # Must zero gradient every training step\n",
    "            opt.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, target)\n",
    "            epoch_train_loss += loss.item()\n",
    "            # Record accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            epoch_train_correct += (preds == target).sum().item()\n",
    "            # Backpropogate\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            counter += 1\n",
    "        # Compute and display statistics\n",
    "        train_loss = epoch_train_loss / counter\n",
    "        correct = epoch_train_correct / len(dataloader.dataset) * 100\n",
    "        \n",
    "        print(f'Epoch: {n} | Training loss: {train_loss:.3f} | Train accuracy: {correct:3f}%')\n",
    "\n",
    "        # ###### VALIDATION ######\n",
    "        \n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_correct = 0\n",
    "        counter = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for data, target in val_dataloader:\n",
    "            with torch.no_grad():\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                outputs = model(data)\n",
    "\n",
    "                loss = criterion(outputs, target)\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                epoch_train_correct += (preds == target).sum().item()\n",
    "                \n",
    "                counter += 1\n",
    "            \n",
    "        train_loss = epoch_train_loss / counter\n",
    "        correct = epoch_train_correct / len(val_dataloader.dataset) * 100\n",
    "        \n",
    "        print(f'Validation loss: {train_loss:.3f} | Validation accuracy: {correct:3f}%')\n",
    "        epoch_time = time.time() - start\n",
    "        print(\"Epoch training time: \", epoch_time, \" seconds\")\n",
    "        total_time += epoch_time\n",
    "        print(\"#\" * 40)\n",
    "    \n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24678d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Run training loop ----\n",
    "EPOCHS = 5\n",
    "\n",
    "print(\"Total training time: \", train_time, \" seconds\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Export our trained model to an ONNX file ----\n",
    "import torch.onnx\n",
    "model.eval()\n",
    "# ONNX stores our model by giving dummy data as an input and recording the operations\n",
    "# Dummy data\n",
    "x = torch.randn((1,3,480,640), requires_grad=True)\n",
    "x = x.to(device)\n",
    "# Forward pass\n",
    "torch_out = model(x)\n",
    "# Save model to onnx\n",
    "torch.onnx.export(model, x, 'onnx_classifier.onnx',\n",
    "                 export_params=True,\n",
    "                 opset_version=10,\n",
    "                 do_constant_folding=True,\n",
    "                 input_names=['input'],\n",
    "                 output_names=['output'],\n",
    "                 dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880836d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
